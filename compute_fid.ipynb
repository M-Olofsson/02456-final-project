{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25507,
     "status": "ok",
     "timestamp": 1701427957435,
     "user": {
      "displayName": "Mattias Olofsson",
      "userId": "01317922821444014401"
     },
     "user_tz": -60
    },
    "id": "P40aNOXGW2hh",
    "outputId": "df7f54a8-29a9-4a03-b168-dca7f1f8c9c4"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchsde\n",
    "from torchdyn.core import NeuralODE\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "from torchcfm.models.unet import UNetModel\n",
    "\n",
    "savedir = \"models/mnist\"\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A4F4GJP7W2hm"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 5\n",
    "\n",
    "trainset = datasets.MNIST(\n",
    "    \"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]),\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L2eAlgDFW2ho"
   },
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "\n",
    "model = UNetModel(dim=(1, 28, 28), num_channels=32, num_res_blocks=1).to(device)\n",
    "score_model = UNetModel(dim=(1, 28, 28), num_channels=32, num_res_blocks=1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(score_model.parameters()))\n",
    "FM = ConditionalFlowMatcher(sigma=sigma)\n",
    "node = NeuralODE(model, solver=\"euler\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250164,
     "status": "ok",
     "timestamp": 1701428920089,
     "user": {
      "displayName": "Mattias Olofsson",
      "userId": "01317922821444014401"
     },
     "user_tz": -60
    },
    "id": "hWTshvGcW2hp",
    "outputId": "32b17f7d-1c96-4001-ac05-fca320c16196"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "468it [02:35,  3.01it/s]\n",
      "468it [02:41,  2.90it/s]\n",
      "468it [02:42,  2.88it/s]\n",
      "468it [02:43,  2.86it/s]\n",
      "468it [02:43,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        x1 = data[0].to(device)\n",
    "        x0 = torch.randn_like(x1)\n",
    "        t, xt, ut, eps = FM.sample_location_and_conditional_flow(x0, x1, return_noise=True)\n",
    "        lambda_t = FM.compute_lambda(t)\n",
    "        vt = model(t, xt)\n",
    "        st = score_model(t, xt)\n",
    "\n",
    "        flow_loss = torch.mean((vt - ut) ** 2)\n",
    "        score_loss = torch.mean((lambda_t * st - eps) ** 2)\n",
    "\n",
    "        loss = flow_loss + score_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RvWzqlpL-qyB"
   },
   "outputs": [],
   "source": [
    "torch.save(score_model,'score_model_10epochs.pt')\n",
    "torch.save(model, 'flow_model_10epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YsgOkfTFCKYx"
   },
   "outputs": [],
   "source": [
    "number_of_images = 100\n",
    "initial_condition = torch.randn(number_of_images, 1, 28, 28).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22912,
     "status": "ok",
     "timestamp": 1701430425289,
     "user": {
      "displayName": "Mattias Olofsson",
      "userId": "01317922821444014401"
     },
     "user_tz": -60
    },
    "id": "AZHcBvTeW2hq",
    "outputId": "b101316b-0030-4f02-fc9b-868568cd08ee"
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.58 GiB. GPU 0 has a total capacty of 5.80 GiB of which 2.19 GiB is free. Including non-PyTorch memory, this process has 3.59 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 420.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmkdir cfm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(num_steps_solver)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m   traj \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_condition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps_solver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_images):\n\u001b[1;32m     12\u001b[0m   img \u001b[38;5;241m=\u001b[39m ToPILImage()(traj[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, j]\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchdyn/core/neuralde.py:100\u001b[0m, in \u001b[0;36mNeuralODE.trajectory\u001b[0;34m(self, x, t_span)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrajectory\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:torch\u001b[38;5;241m.\u001b[39mTensor, t_span:Tensor):\n\u001b[1;32m     99\u001b[0m     x, t_span \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_integration(x, t_span)\n\u001b[0;32m--> 100\u001b[0m     _, sol \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sol\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchdyn/numerics/odeint.py:85\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(f, x, t_span, solver, atol, rtol, t_stops, verbose, interpolator, return_all_eval, save_at, args, seminorm)\u001b[0m\n\u001b[1;32m     83\u001b[0m \t\twarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting tolerances has no effect on fixed-step methods\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \t\u001b[38;5;66;03m# instantiate save_at tensor\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fixed_odeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_at\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stepping_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     87\u001b[0m \tt \u001b[38;5;241m=\u001b[39m t_span[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchdyn/numerics/odeint.py:428\u001b[0m, in \u001b[0;36m_fixed_odeint\u001b[0;34m(f, x, t_span, solver, save_at, args)\u001b[0m\n\u001b[1;32m    426\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(t_span) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 428\u001b[0m \t_, x, _ \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \tt \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m+\u001b[39m dt\n\u001b[1;32m    431\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misclose(t, save_at)\u001b[38;5;241m.\u001b[39msum():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchdyn/numerics/solvers/ode.py:69\u001b[0m, in \u001b[0;36mEuler.step\u001b[0;34m(self, f, x, t, dt, k1, args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, x, t, dt, k1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k1 \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: k1 \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     x_sol \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m dt \u001b[38;5;241m*\u001b[39m k1\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, x_sol, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchdyn/core/defunc.py:77\u001b[0m, in \u001b[0;36mDEFunc.forward\u001b[0;34m(self, t, x, args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# regular forward\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m: x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigher_order_forward(t, x)\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/unet.py:925\u001b[0m, in \u001b[0;36mUNetModelWrapper.forward\u001b[0;34m(self, t, x, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/unet.py:626\u001b[0m, in \u001b[0;36mUNetModel.forward\u001b[0;34m(self, t, x, y)\u001b[0m\n\u001b[1;32m    624\u001b[0m h \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_blocks:\n\u001b[0;32m--> 626\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m     hs\u001b[38;5;241m.\u001b[39mappend(h)\n\u001b[1;32m    628\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddle_block(h, emb)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/unet.py:69\u001b[0m, in \u001b[0;36mTimestepEmbedSequential.forward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m     67\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x, emb)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/unet.py:273\u001b[0m, in \u001b[0;36mAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/nn.py:118\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(func, inputs, params, flag)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag:\n\u001b[1;32m    117\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(params)\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/nn.py:130\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, length, *args)\u001b[0m\n\u001b[1;32m    128\u001b[0m ctx\u001b[38;5;241m.\u001b[39minput_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args[length:])\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 130\u001b[0m     output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_tensors\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/unet.py:279\u001b[0m, in \u001b[0;36mAttentionBlock._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    277\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(b, c, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    278\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x))\n\u001b[0;32m--> 279\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqkv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_out(h)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (x \u001b[38;5;241m+\u001b[39m h)\u001b[38;5;241m.\u001b[39mreshape(b, c, \u001b[38;5;241m*\u001b[39mspatial)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchcfm/models/unet/unet.py:324\u001b[0m, in \u001b[0;36mQKVAttentionLegacy.forward\u001b[0;34m(self, qkv)\u001b[0m\n\u001b[1;32m    322\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mreshape(bs \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, ch \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m, length)\u001b[38;5;241m.\u001b[39msplit(ch, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    323\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(math\u001b[38;5;241m.\u001b[39msqrt(ch))\n\u001b[0;32m--> 324\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbct,bcs->bts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# More stable with f16 than dividing afterwards\u001b[39;00m\n\u001b[1;32m    327\u001b[0m weight \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39msoftmax(weight\u001b[38;5;241m.\u001b[39mfloat(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(weight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    328\u001b[0m a \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbts,bcs->bct\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight, v)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.58 GiB. GPU 0 has a total capacty of 5.80 GiB of which 2.19 GiB is free. Including non-PyTorch memory, this process has 3.59 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 420.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#Noise = 0\n",
    "\n",
    "for i, num_steps_solver in enumerate([1,10,100,1000]):\n",
    "\n",
    "  os.system(f'mkdir cfm_{str(num_steps_solver)}_3')\n",
    "  with torch.no_grad():\n",
    "    traj = node.trajectory(\n",
    "          initial_condition,\n",
    "          t_span=torch.linspace(0, 1, num_steps_solver + 1).to(device),\n",
    "      )\n",
    "  for j in range(number_of_images):\n",
    "    img = ToPILImage()(traj[-1, j].clip(-1, 1))\n",
    "    filename = f'cfm_{str(num_steps_solver)}_3/{j}.png'\n",
    "    img.save(filename, 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MY10PiNWW2hs"
   },
   "outputs": [],
   "source": [
    "class SDE(torch.nn.Module):\n",
    "    noise_type = \"diagonal\"\n",
    "    sde_type = \"ito\"\n",
    "\n",
    "    def __init__(self, ode_drift, score, epsilon = 1, input_size=(1, 28, 28), reverse=False):\n",
    "        super().__init__()\n",
    "        self.drift = ode_drift\n",
    "        self.score = score\n",
    "        self.reverse = reverse\n",
    "        self.epsilon = torch.tensor(epsilon)\n",
    "    # Drift\n",
    "    def f(self, t, y):\n",
    "        y = y.view(-1, 1, 28, 28)\n",
    "        if self.reverse:\n",
    "            t = 1 - t\n",
    "            return -self.drift(t, y) + self.score(t, y)\n",
    "        return self.drift(t, y).flatten(start_dim=1) + self.epsilon * self.score(t, y).flatten(start_dim=1)\n",
    "\n",
    "    # Diffusion\n",
    "    def g(self, t, y):\n",
    "        y = y.view(-1, 1, 28, 28)\n",
    "        return torch.sqrt(self.epsilon) * (torch.ones_like(t) * torch.ones_like(y)).flatten(start_dim=1) * sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 304574,
     "status": "ok",
     "timestamp": 1701430900960,
     "user": {
      "displayName": "Mattias Olofsson",
      "userId": "01317922821444014401"
     },
     "user_tz": -60
    },
    "id": "F3TGg4JWW2hs",
    "outputId": "4ad6ef46-1b02-4ab2-94d9-2e6a9ca9d340"
   },
   "outputs": [],
   "source": [
    "noise_coeff = 0.25\n",
    "\n",
    "sde = SDE(model, score_model,epsilon = noise_coeff)\n",
    "for i, num_steps_solver in enumerate([1,10,100,1000]):\n",
    "\n",
    "  os.system(f'mkdir sde_{str(num_steps_solver)}_{str(noise_coeff)}')\n",
    "  with torch.no_grad():\n",
    "      sde_traj = torchsde.sdeint(\n",
    "          sde,\n",
    "          # x0.view(x0.size(0), -1),\n",
    "          torch.flatten(initial_condition, start_dim = 1),\n",
    "          ts=torch.linspace(0, 1, num_steps_solver + 1).to(device),\n",
    "          dt=1/(num_steps_solver),\n",
    "      )\n",
    "  for j in range(number_of_images):\n",
    "    img = ToPILImage()(sde_traj[-1, j].view([ 1, 28, 28]).clip(-1, 1))\n",
    "    filename = f'sde_{str(num_steps_solver)}_{str(noise_coeff)}/{j}.png'\n",
    "    img.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 304797,
     "status": "ok",
     "timestamp": 1701431250510,
     "user": {
      "displayName": "Mattias Olofsson",
      "userId": "01317922821444014401"
     },
     "user_tz": -60
    },
    "id": "lnIyH6ljW2hs",
    "outputId": "b716f775-1e91-4181-d1be-d490e4ea321d"
   },
   "outputs": [],
   "source": [
    "noise_coeff = 0.5\n",
    "\n",
    "generated_images_SDE_2 = torch.zeros([5, 100, 1, 28, 28])\n",
    "sde = SDE(model, score_model,epsilon = noise_coeff)\n",
    "for i, num_steps_solver in enumerate([1,10,100,1000]):\n",
    "\n",
    "  os.system(f'mkdir sde_{str(num_steps_solver)}_{str(noise_coeff)}')\n",
    "  with torch.no_grad():\n",
    "      sde_traj = torchsde.sdeint(\n",
    "          sde,\n",
    "          # x0.view(x0.size(0), -1),\n",
    "          torch.flatten(initial_condition, start_dim = 1),\n",
    "          ts=torch.linspace(0, 1, num_steps_solver + 1).to(device),\n",
    "          dt=1/(num_steps_solver),\n",
    "      )\n",
    "  for j in range(number_of_images):\n",
    "    img = ToPILImage()(sde_traj[-1, j].view([ 1, 28, 28]).clip(-1, 1))\n",
    "    filename = f'sde_{str(num_steps_solver)}_{str(noise_coeff)}/{j}.png'\n",
    "    img.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 297221,
     "status": "ok",
     "timestamp": 1701431547728,
     "user": {
      "displayName": "Mattias Olofsson",
      "userId": "01317922821444014401"
     },
     "user_tz": -60
    },
    "id": "QAzntgK6W2ht",
    "outputId": "9d1d509e-af81-4a29-d331-8ea926013677"
   },
   "outputs": [],
   "source": [
    "noise_coeff = 1\n",
    "\n",
    "generated_images_SDE_3 = torch.zeros([5, 100, 1, 28, 28])\n",
    "sde = SDE(model, score_model,epsilon = noise_coeff)\n",
    "for i, num_steps_solver in enumerate([1,10,100,1000]):\n",
    "\n",
    "  os.system(f'mkdir sde_{str(num_steps_solver)}_{str(noise_coeff)}')\n",
    "  with torch.no_grad():\n",
    "      sde_traj = torchsde.sdeint(\n",
    "          sde,\n",
    "          # x0.view(x0.size(0), -1),\n",
    "          torch.flatten(initial_condition, start_dim = 1),\n",
    "          ts=torch.linspace(0, 1, num_steps_solver + 1).to(device),\n",
    "          dt=1/(num_steps_solver),\n",
    "      )\n",
    "  for j in range(number_of_images):\n",
    "    img = ToPILImage()(sde_traj[-1, j].view([ 1, 28, 28]).clip(-1, 1))\n",
    "    filename = f'sde_{str(num_steps_solver)}_{str(noise_coeff)}/{j}.png'\n",
    "    img.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15XI-HebyJl3"
   },
   "outputs": [],
   "source": [
    "noise_coeff = 2\n",
    "\n",
    "sde = SDE(model, score_model,epsilon = noise_coeff)\n",
    "for i, num_steps_solver in enumerate([1,10,100,1000]):\n",
    "\n",
    "  os.system(f'mkdir sde_{str(num_steps_solver)}_{str(noise_coeff)}')\n",
    "  with torch.no_grad():\n",
    "      sde_traj = torchsde.sdeint(\n",
    "          sde,\n",
    "          # x0.view(x0.size(0), -1),\n",
    "          torch.flatten(initial_condition, start_dim = 1),\n",
    "          ts=torch.linspace(0, 1, num_steps_solver + 1).to(device),\n",
    "          dt=1/(num_steps_solver),\n",
    "      )\n",
    "  for j in range(number_of_images):\n",
    "    img = ToPILImage()(sde_traj[-1, j].view([ 1, 28, 28]).clip(-1, 1))\n",
    "    filename = f'sde_{str(num_steps_solver)}_{str(noise_coeff)}/{j}.png'\n",
    "    img.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ydg_Y7_UK9eD",
    "outputId": "6a7686fc-e683-407d-ba54-e93a4110581b"
   },
   "outputs": [],
   "source": [
    "noise_coeff = 4\n",
    "\n",
    "sde = SDE(model, score_model,epsilon = noise_coeff)\n",
    "for i, num_steps_solver in enumerate([1,10,100,1000]):\n",
    "\n",
    "  os.system(f'mkdir sde_{str(num_steps_solver)}_{str(noise_coeff)}')\n",
    "  with torch.no_grad():\n",
    "      sde_traj = torchsde.sdeint(\n",
    "          sde,\n",
    "          # x0.view(x0.size(0), -1),\n",
    "          torch.flatten(initial_condition, start_dim = 1),\n",
    "          ts=torch.linspace(0, 1, num_steps_solver + 1).to(device),\n",
    "          dt=1/(num_steps_solver),\n",
    "      )\n",
    "  for j in range(number_of_images):\n",
    "    img = ToPILImage()(sde_traj[-1, j].view([ 1, 28, 28]).clip(-1, 1))\n",
    "    filename = f'sde_{str(num_steps_solver)}_{str(noise_coeff)}/{j}.png'\n",
    "    img.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63OkPH2MMBZv"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "###Compute FID scores for the different noise levels\n",
    "####################################################\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a grid view 10x10 for all SDE samples for different steps and noise\n",
    "for s in [1,10,100,1000]:\n",
    "    for e in [0.25,0.5,1,2,4]:\n",
    "\n",
    "        grid = np.zeros((28*10,28*10))\n",
    "        for i in range(10):\n",
    "            for j in range(10):\n",
    "                grid[i*28:(i+1)*28,j*28:(j+1)*28] = np.asarray(Image.open(f'sde_{s}_{e}/{i*10+j}.png'))\n",
    "\n",
    "        grid = Image.fromarray(grid.astype(np.uint8))\n",
    "        grid.save(f'sde_{s}_{e}.png', 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a grid view 10x10 for all CFM samples for different steps\n",
    "for s in [1,10,100,1000]:\n",
    "\n",
    "    grid = np.zeros((28*10,28*10))\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            grid[i*28:(i+1)*28,j*28:(j+1)*28] = np.asarray(Image.open(f'cfm_{s}/{i*10+j}.png'))\n",
    "\n",
    "    grid = Image.fromarray(grid.astype(np.uint8))\n",
    "    grid.save(f'cfm_{s}.png', 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDE Steps=1 Noise=0.25 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "100%|██████████| 1200/1200 [02:19<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  229.08294272178728\n",
      "SDE Steps=1 Noise=0.5 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1200/1200 [02:22<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  232.59970415772216\n",
      "SDE Steps=1 Noise=1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  231.355337364466\n",
      "SDE Steps=1 Noise=2 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.83it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  239.6984008614937\n",
      "SDE Steps=1 Noise=4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.14it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  249.34611093272713\n",
      "SDE Steps=10 Noise=0.25 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.15it/s]\n",
      "100%|██████████| 1200/1200 [02:26<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  217.9432515094471\n",
      "SDE Steps=10 Noise=0.5 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.01it/s]\n",
      "100%|██████████| 1200/1200 [02:26<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  220.78699357544397\n",
      "SDE Steps=10 Noise=1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.84it/s]\n",
      "100%|██████████| 1200/1200 [02:27<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  220.18953653128762\n",
      "SDE Steps=10 Noise=2 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  219.00477173587524\n",
      "SDE Steps=10 Noise=4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  220.01367149273113\n",
      "SDE Steps=100 Noise=0.25 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  217.72834674076523\n",
      "SDE Steps=100 Noise=0.5 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.93it/s]\n",
      "100%|██████████| 1200/1200 [02:27<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  217.25170917289498\n",
      "SDE Steps=100 Noise=1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1200/1200 [02:26<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  216.10583703657002\n",
      "SDE Steps=100 Noise=2 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.02it/s]\n",
      "100%|██████████| 1200/1200 [02:26<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  217.68637068665063\n",
      "SDE Steps=100 Noise=4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.83it/s]\n",
      "100%|██████████| 1200/1200 [02:26<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  224.02308072973932\n",
      "SDE Steps=1000 Noise=0.25 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.01it/s]\n",
      "100%|██████████| 1200/1200 [02:26<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  214.9567448903651\n",
      "SDE Steps=1000 Noise=0.5 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.93it/s]\n",
      "100%|██████████| 1200/1200 [02:26<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  216.31224074639096\n",
      "SDE Steps=1000 Noise=1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.81it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  217.28380054001673\n",
      "SDE Steps=1000 Noise=2 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "100%|██████████| 1200/1200 [02:23<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  219.0015017768356\n",
      "SDE Steps=1000 Noise=4 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  226.0063324130836\n"
     ]
    }
   ],
   "source": [
    "#FID for all SDE samples with different steps and noise. data is all mnist(60k) dataset\n",
    "for s in [1,10,100,1000]:\n",
    "    for e in [0.25,0.5,1,2,4]:\n",
    "        print(f\"SDE Steps={s} Noise={e} :\")\n",
    "        os.system(f\"python3 -m pytorch_fid sde_{s}_{e} data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFM Steps=1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.12it/s]\n",
      "100%|██████████| 1200/1200 [02:19<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  330.5893410417374\n",
      "CFM Steps=10 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.04it/s]\n",
      "100%|██████████| 1200/1200 [02:21<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  210.1260097360542\n",
      "CFM Steps=100 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.02it/s]\n",
      "100%|██████████| 1200/1200 [02:24<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  215.87934161050342\n",
      "CFM Steps=1000 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  215.90738216737705\n"
     ]
    }
   ],
   "source": [
    "#FID for all CFM samples with different steps. data is all mnist(60k) dataset\n",
    "for s in [1,10,100,1000]:\n",
    "        print(f\"CFM Steps={s} :\")\n",
    "        os.system(f\"python3 -m pytorch_fid cfm_{s} data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFM Steps=1 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 1200/1200 [02:20<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  318.3557859058728\n",
      "CFM Steps=10 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1200/1200 [02:23<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  198.68773875984942\n",
      "CFM Steps=100 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1200/1200 [02:24<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  202.0917301702733\n",
      "CFM Steps=1000 :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.09it/s]\n",
      "100%|██████████| 1200/1200 [02:25<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  201.47718097833814\n"
     ]
    }
   ],
   "source": [
    "#FID for all CFM samples with different steps. data is all mnist(60k) dataset\n",
    "for s in [1,10,100,1000]:\n",
    "        print(f\"CFM Steps={s} :\")\n",
    "        os.system(f\"python3 -m pytorch_fid cfm_{s}_2 data\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/atong01/conditional-flow-matching/blob/main/examples/notebooks/mnist_example.ipynb",
     "timestamp": 1701338628860
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
